# SPDX-FileCopyrightText: 2024 SAP SE or an SAP affiliate company and Gardener contributors
#
# SPDX-License-Identifier: Apache-2.0

global:
  s3Configuration: {}
#    server:
#      endpoint: "tbd"
#      ssl: true
#    bucketName: testmachinery
#    accessKey: IbnGHa4V6ypsm
#    secretKey: l9rJ0XR65Rkvc9g9fyOf

controller:
  hostPath: ""
  image: europe-docker.pkg.dev/gardener-project/releases/testmachinery/testmachinery-controller
  tag: latest
  pullPolicy: IfNotPresent

  verbosity: 3

  serviceAccountName: testmachinery-controller

  healthEndpointPort: 8081
  metricsEndpointPort: 8080
  enableLeaderElection: false
  maxConcurrentSyncs: 1
  webhook:
    port: 9443
  argoHealthCheckInterval: 1m

  tls:
    caBundle: |
      -----BEGIN CERTIFICATE-----
      ...
      -----END CERTIFICATE-----
    crt: |
      -----BEGIN CERTIFICATE-----
      ...
      -----END CERTIFICATE-----
    key: |
      -----BEGIN RSA PRIVATE KEY-----
      ...
      -----END RSA PRIVATE KEY-----

testmachinery:
  testdefPath: .test-defs
  local: false
  insecure: false
  disableCollector: false
  cleanWorkflowPods: false
#  prepareImage: ""
#  baseImage: ""

  locations:
    excludeDomains: [ ]

  landscapeMappings: []
#    - namespace: default
#      apiServerUrl: https://api.server.com
#      audience: dev
#      expirationSeconds: 7200
#      allowUntrustedUsage: false

  github:
    cache:
      cacheDir: /tmp/tm/cache
      cacheDiskSizeGB: 5
      maxAgeSeconds: 60
    credentials: "" # base64 encoded secrets


  imagePullSecrets: [ ]
  # - name: myDockerPullSecretName
  #   dockerconfigjson: base64 encoded dockerconfigjson

#  esConfiguration:
#    endpoint: https:...:9200
#    username: user
#    password: my-password


reserve-excess-capacity:
  enabled: true
  images:
    reserve-excess-capacity: gcr.io/google_containers/pause-amd64:3.1
  replicas: 5
  resources:
    requests:
      cpu: "1000m"
      memory: "1000Mi"
    limits:
      cpu: "1000m"
      memory: "1000Mi"

argo:
  images:
    argo-workflow-controller: quay.io/argoproj/workflow-controller:v3.5.12
    argo-executor: quay.io/argoproj/argoexec:v3.5.12
    argo-server: quay.io/argoproj/argocli:v3.5.12

  argo:
    name: workflow-controller
    executor:
      waitContainerResources:
        requests:
          cpu: 50m
          memory: 150Mi
        limits:
          cpu: 100m
          memory: 300Mi

    resources: {}
    # requests:
    #   cpu: 200m
    #   memory: 256Mi
    # limits:
    #   cpu: 1
    #   memory: 1Gi

    logging: {}
      # if grafana is specified, default links to a given instance will be injected for both pods as well as workflow
      # grafana:
        # host: "grafana.example.com"
        # https: true
  #    additionalLinks:
  #    - name: Example Workflow Link
  #      scope: workflow
  #      url: http://logging-facility?namespace=${metadata.namespace}&workflowName=${metadata.name}
  #    - name: Example Pod Link
  #      scope: pod
  #      url: http://logging-facility?namespace=${metadata.namespace}&podName=${metadata.name}
  configmap:
    name: tm-config

  argoserver:
    ingress:
      enabled: true
      name: "argo-server"
      host: "argo.example.com"
    #    annotations: { }
    #    labels: { }
    serviceType: ClusterIP

  objectStorage:
    keyPrefix: "testmachinery"
    secret:
      name: "s3-secret"

logging:
  global:
    loggingNamespace: logging
    loggingEnabled: true
  promtail:
    rbac:
      pspEnabled: false
    image:
      repository: grafana/promtail
      tag: 2.0.0
  loki:
    rbac:
      pspEnabled: false
    image:
      repository: grafana/loki
      tag: 2.0.0
    persistence:
      storageClassName: default
